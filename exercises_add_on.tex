\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
%\usepackage{amssymb}
\usepackage{bbm}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{hyperref}

\usepackage{exsheets}
%\SetupExSheets{counter-format=qu}
\SetupExSheets{
  headings = block-subtitle ,
  headings-format = \normalsize\bfseries\sffamily ,
  % needs v0.16 2014/09/14 to work:
  subtitle-format = \normalsize\bfseries\sffamily
}

\SetupExSheets{
  counter-within = section ,
  counter-format = se.qu\IfQuestionSubtitleT{:} ,
}

\geometry{a4paper, margin=2cm}

\usepackage{cprotect}

\usepackage{xcolor}
\definecolor{maroon}{cmyk}{0, 0.87, 0.68, 0.32}
\definecolor{halfgray}{gray}{0.55}
\definecolor{ipython-frame}{RGB}{207, 207, 207}
\definecolor{ipython-bg}{RGB}{247, 247, 247}
\definecolor{ipython-red}{RGB}{186, 33, 33}
\definecolor{ipython-green}{RGB}{0, 200, 0}
\definecolor{ipython-cyan}{RGB}{64, 128, 128}
\definecolor{ipython-purple}{RGB}{170, 34, 255}

\usepackage{listings}
\lstdefinelanguage{iPython}{
	morekeywords={access,and,del,except,exec,in,is,lambda,not,or,raise},
	morekeywords=[2]{for,print,abs,all,any,basestring,bin,bool,bytearray,callable,chr,classmethod,cmp,compile,complex,delattr,dict,dir,divmod,enumerate,eval,execfile,file,filter,float,format,frozenset,getattr,globals,hasattr,hash,help,hex,id,input,int,isinstance,issubclass,iter,len,list,locals,long,map,max,memoryview,min,next,object,oct,open,ord,pow,property,range,reduce,reload,repr,reversed,round,set,setattr,slice,sorted,staticmethod,str,sum,super,tuple,type,unichr,unicode,vars,xrange,zip,apply,buffer,coerce,intern,elif,else,if,continue,break,while,class,def,return,try,except,import,finally,try,except,from,global,pass, True, False},
	sensitive=true,
	morecomment=[l]\#,%
	morestring=[b]',%
	morestring=[b]",%
	moredelim=**[is][\color{black}]{@@}{@@},
	identifierstyle=\color{black}\footnotesize\ttfamily,
	commentstyle=\color{ipython-cyan}\footnotesize\itshape\ttfamily,
	stringstyle=\color{ipython-red}\footnotesize\ttfamily,
	keepspaces=true,
	showspaces=false,
	showstringspaces=false,
	rulecolor=\color{ipython-frame},
	frame=single,
	frameround={t}{t}{t}{t},
	backgroundcolor=\color{ipython-bg},
	basicstyle=\footnotesize\ttfamily,
	keywordstyle=[2]\color{ipython-green}\bfseries\footnotesize\ttfamily, 
	keywordstyle=\color{ipython-purple}\bfseries\footnotesize\ttfamily
}

\lstdefinelanguage{iOutput} {
	sensitive=true,
	identifierstyle=\color{black}\small\ttfamily,
	stringstyle=\color{ipython-red}\small\ttfamily,
	keepspaces=true,
	showspaces=false,
	showstringspaces=false,
	rulecolor=\color{ipython-frame},
	basicstyle=\small\ttfamily,
}

\lstnewenvironment{ipython}[1][]{\lstset{language=iPython,mathescape=true,escapeinside={*@}{@*}}%
}{%
}

\lstnewenvironment{ioutput}[1][]{\lstset{language=iOutput,mathescape=true,escapeinside={*@}{@*}}%
}{%
}

\title{Addons with Python Exercises}
\author{Matteo Sani}

\begin{document}
\maketitle

\section{Stochastic Simulation}
In science, we are often more interested in the distribution of a set of outcomes rather than a single event. This may be the probability distribution of a molecule diffusing a specific distance as a function of time, or the price change of a very exotic derivative.

Stochastic simulations allow us to generate a series of experiments on a system in which one step is governed by random chance. These simulations often boil down to flipping a coin to dictate if said step will occur or not.

Of course, sitting in your office chair flipping a coin over and over again is not how one should do a simulation. To get a sense of the probability distribution of some outcome, we often have to simulate the process thousands of times. This means that we need to know how to make our computers do the heavy lifting.

It's often easy to forget just how powerful modern computers can be. What once required a serious computational cluster only twenty years ago can now be done on a 10 mm thick compartment made of rose-gold colored aluminium. 

%FIXME few words about mean and C.L.

\subsection{1D Random Walk}
The Random Walk in one dimension is a model for each process which have simple binary outcomes.

The 1D random walk can be used to model how a gambler plays a game such as roulette in a casino. The idea in such games is that the gambler places a small stake on each game (say 1€). When the game is played the gambler will either loose and the total amount of money he has will thus decrease by one unit, or alternatively, he will win the game and in that case he wins back his stake and a prize, which we will set as 1€. As you can see if the gambler repeats this process of staking money and playing the amount of money he has will undergo a random walk in one dimension, since the outcome will be either 1 or -1.

\begin{question}
Code a function that simulate a 1D random walk. 

\noindent
\textbf{Hint:} we can decide whether to walk left or right by flipping a coin and seeing if it comes up \emph{heads} or \emph{tails}.
\end{question}

\subsubsection{Simulating a Gambler}

Importantly there is a difference between the gambler and the 1D random walk, however. The gambler usually only has a finite amount of money to gamble with. If he looses a large number of games he is therefore forced to stop playing. Similarly, the gambler may also have some target for how much money he would like to win. In other words, he should have some figure $N$€, which is more than the amount of money he entered the casino with. He will stop gambling once he has $N$€ in his pocket.

\begin{question}
Determine with a simulation the probabilities whether the gambler leaves the casino with zero or with $N$€.

Essentially we start the gambler with $X$€ and simulate the process of him playing the game only stopping once he has reached one of the two thresholds.

Write a function called gambler that simulates this procedure, taking three arguments:
\begin{itemize}
\item \texttt{start}: the amount of money the gambler starts with; \item \texttt{n}: the target amount of money that the gambler wants to win;
\item \texttt{p}: the probability of winning each individual game the gambler plays.
\end{itemize}
\end{question}

We can also use simulation to determine how many spins of the wheel the gambler will play before leaving the casino (i.e. \emph{hitting time}).
In other words we want to calculate the number of steps the random walk takes before arriving in one of the two threshold states.

\begin{question}
Write another function that simulates the changes in the amount of money the gambler has and that returns the number of spins of the wheel that take place.
\end{question}

\subsection{Martingale Examples}
Suppose you play the following series of games. In game $i, i = 1, 2,\ldots$, you bet \$1 and roll a fair die. If the outcome is $\{1,2\}$ you win \$1, if it is $\{3,4\}$ nothing happens, and if the outcome is $\{5,6\}$ you lose \$1.
Let $X_i$ be a random variable representing the amount of money you win or lose in bet $i$, this kind of game is said to be **fair** since

$$\mathbb{E}[X_i]= \sum_{\Omega}p(\omega)\cdot x(\omega) = \frac{2}{6}\cdot 1 + \frac{2}{6}\cdot 0 + \frac{2}{6}\cdot -1 = 0\;\forall i$$
so no unbalance between losses or wins.

Now define another random variable $Z_n = \sum_{i=1}^{n} X_i$, i.e. the amount of money held at the $n$-th game.

$Z_n$ is a martingale and $\mathbb{E}[Z_n|X_1,\ldots, X_{n-1}] = Z_{n-1}$.

\paragraph{Proof}

\begin{equation}
	\begin{aligned}
		\mathbb{E}[Z_n|X_1,\ldots, X_{n-1}] &= \mathbb{E}[X_1 +\ldots + X_n|X_1,\ldots, X_{n-1}] \\
		& = \underbrace{\mathbb{E}[X_1|X_1,\ldots, X_{n-1}]}_{X_1} + \ldots + \underbrace{\mathbb{E}[X_{n-1}|X_1,\ldots, X_{n-1}]}_{X_{n-1}} + \underbrace{\mathbb{E}[X_n|X_1,\ldots, X_{n-1}]}_{\mathbb{E}[X_n]=0} \\
		& = \mathbb{E}[X_1|X_1,\ldots, X_{n-1}] + \ldots + \mathbb{E}[X_{n-1}|X_1,\ldots, X_{n-1}] + 0 = Z_{n-1}
	\end{aligned}
\end{equation}

\begin{question}
Using Monte Carlo simulation implement the game described in the text and check that the expected gain is indeed null.
\end{question}

\begin{question}
An unbiased random walk (in any number of dimensions) is another example of a martingale.

In higher dimensions, the set of randomly walked points has interesting geometric properties. In fact, one gets a discrete \emph{fractal}, that is, a set that exhibits stochastic self-similarity on large scales.

Implement a 2D random walk simulation and plot one possible realization.
\end{question}

\subsection{Simulating Stochastic Differential Equations}

Consider a generic stochastic differential equation (SDE)

\begin{equation}
dX(t) = \mu(t,X(t))dt + \sigma(t,X(t))dW(t)
\label{eq:sde}
\end{equation}

The Monte Carlo simulation of such a process can be carried out according to the \emph{Euler scheme} as follows: conisider the value of $X$ at time $t=t_i$, the value compute $X(t_{i+1})$ is evaluated from the dynamics of X (Eq.\ref{eq:sde}), setting $\Delta t = t_{i+1} - t_{i}$, and sampling from a standard normal $\mathcal{N}(0,1)$ in order to "evolve" the stochastic term $dW$
\begin{equation}
X(t_{i+1}) = X(t_i) + \mu(t_i,X(t_i))\Delta t + \sigma(t_i,X(t_i))\sqrt{\Delta t}\mathcal{N}(0,1)
\end{equation}

In the specific case of a simple brownian motion the dynamics is given by
\begin{equation}
dW = \sqrt{dt}\mathcal{N}(0,1)
\end{equation}
so
\begin{equation}
W(t+dt) = W(t) + \sqrt{dt}\mathcal{N}(0,1)
\end{equation}
or
\begin{equation}
W(t) = \sum_{t_0}^{t} \sqrt{dt}\mathcal{N}(0,1)
\end{equation}

Figure|\ref{fig:brownian_motion} reports two realization of the Brownian motion simulated according to the Euler scheme.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.5\linewidth]{addons/brownian_motion}
\end{center}
\label{fig:brownian_motion}
\end{figure}

\begin{question}
Using the Euler scheme simulate the 4-months (with daily steps) evolution of a Geometric Brownian Motion stochastic process with initial value $S_0=100$, $\mu=0.005$, and $\sigma=0.05$.
\end{question}

\cprotEnv\begin{question}
This \href{https://github.com/matteosan1/advanced_financial_modeling/raw/master/input_files}{file} contains a thousand 10-day realizations (with 0.1 day step) of historical price data of a single asset, assume that all the time series are different realizations of the same stochastic process.
\begin{enumerate}
\item Make two figures: the first should contain one realization as a function of time, in the second plot the first 50 realizations together as a function of time (\emph{label the axes appropriately}).
\item In two separated plots report the mean and the variance of the stock prices as a function of time (\emph{label the axes appropriately}).
\item Perform the variable change $X_{n+1}=\log\left(\cfrac{S_{n+1}}{S_n}\right)$ on $S_{n+1} = S_ne^{(\mu-0.5\sigma^2)\Delta t + \sigma\sqrt{\Delta t}Z}$ to rewrite the model into a simpler form. 
	\begin{enumerate}
	\item Is the resulting dynamics linear ? Prove it, or give a counterexample; 
	\item is the resulting system time-invariant ? Prove it, or give a counterexample.
	\end{enumerate}
\item Apply again the same transformation $X_{n+1}=\log\left(\frac{S_{n+1}}{S_n}\right)$ to data this time. Plot both the mean and the variance of the transformed realizations as a function of time.
\end{enumerate}

\noindent
\textbf{Hint:} the input file is a binary file that can be loaded back using \texttt{numpy} as follows (replace the URL from the link above):
\begin{ipython}
import numpy as np

path = np.DataSource("https://github.com/matteosan1/...../input_files")
S = np.load(path.open("stock_2023.npy", "rb"))
\end{ipython}
\end{question}

\begin{question}
The Heston model can be considered an extension of the Black and Scholes model where the volatility of the underlying asset is not constant, nor even deterministic, but follows a random process.

The basic Heston model assumes that $S_t$, the price of the asset, follows
\begin{equation}
dS_{t}=\mu S_{t}\,dt+{\sqrt {\nu _{t}}}S_{t}\,dW_{t}^{S}
\end{equation}
where the volatility 
\begin{equation}
{\displaystyle d\nu _{t}=\kappa (\theta -\nu _{t})\,dt+\xi {\sqrt {\nu _{t}}}\,dW_{t}^{\nu },}
\end{equation}
and 
\begin{equation}
W_{t}^{S},W_{t}^{\nu }
\end{equation} 
are Wiener processes with correlation $\rho$.

The model has five parameters:
\begin{itemize}
\item $\nu _0$, the initial variance;
\item $\theta$, the long variance of the price; as $t$ tends to infinity, the expected value of $\nu_t$ tends to $\theta$;
\item $\rho$, the correlation of the two Wiener processes;
\item $\kappa$, the rate at which $\nu_t$ reverts to $\theta$;
\item $\xi$, the volatility of the volatility, which determines the variance of $\nu_t$.
\end{itemize}

Using the Euler scheme simulate a possible realization for $S_t$ and $\sigma_t$ using the parameters: $S_0=100$, $\mu=0.25$, $T=3$, $\nu_0=0.05$, $\kappa=1.2$, $\theta=0.10$, $\xi=0.593$, $\rho=-0.5$.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.8\linewidth]{addons/heston}
\end{center}
\label{fig:heston}
\end{figure}
\end{question}

\section{Interest Rate Swap as FRAs}

The swap payoff 

\begin{equation}
	\sum_{i=\alpha+1}^{\beta} D(t,T_i)N \tau_i \left[K-L(T_{i-1},T_i)\right]
	\label{eq:payoff_payer_irs}
\end{equation}	
can be re-interpreted as a portfolio of FRAs. Indeed using the payoff of a FRA
\begin{equation}
	\textbf{FRA}= N\tau P(t,S)(K - F(t;T,S))
	\label{eq:fram_payoff_withF}
\end{equation}
the Receiver IRS payoff can be expressed like
\begin{equation}
	\begin{aligned}
		\textbf{RFS}&(t,T,\tau,N,K) = 	N\sum_{i=\alpha+1}^{\beta}\mathbb{E}^Q[D(t,S)\tau_i(K - L(T_{i-1},T_i))]=\\
		&=N\sum_{i=\alpha+1}^{\beta}\tau_i P(t,T_i)(K-F(t;T_{i-1},T_i))\\
		&=N\sum_{i=\alpha+1}^{\beta}\tau_i KP(t,T_i)-N\sum_{i=\alpha+1}^{\beta}(P(t,T_{i-1})-P(t,T_i)) \\
		&=N\sum_{i=\alpha+1}^{\beta}\tau_i KP(t,T_i)-NP(t,T_\alpha)+NP(t,T_\beta)
	\end{aligned}
\label{eq:swap_as_sum_fra}
\end{equation}

Clearly not all the FRAs in the swap, when it has zero value, will have zero value each (\emph{except for the degenerate case of flat yield curve}): some of them will have positive NPV, some other negative; the only constraint being their sum to be zero.

\begin{question}
Implementing a class or a function that represents an interest rate swap shows that:
\begin{enumerate}
\item In a \emph{Payer Swap} with an increasing yield curve the first FRAs will have negative value, the last positive. 
\item In a \emph{Payer Swap} with a decreasing yield curve the first FRAs will have positive value, the last negative.
\end{enumerate}
\end{question}

\section{Algorithmic Differentiation}

\emph{Algorithmic Differentiation} (AD), also known as \emph{automatic differentiation}, is a mathematical, computer science technique for computing accurate sensitivities quickly. There are two main modes, namely \textbf{tangent mode} and \text{adjoint mode}. For many models, \emph{adjoint AD (AAD)} can compute sensitivities from to 10x to 1000x faster than numerical bumping or finite differences. AD operates directly on analytics and each line of code is differentiated. Clearly it can be applied to a single trade or a portfolio (or vector) of trades.

If for example we have a computer algorithm that computes $y$ via multiple nested operations such as $y = h(g(f(x)))$ we could illustrate the series of operations as,
\begin{equation}
x\rightarrow f(x) \rightarrow g(f(x)) \rightarrow h(g(f(x))) \rightarrow y
\end{equation}

Working forwards from the input value $x$, we can compute the derivative of each operation and use the \emph{chain rule} to compute the total derivative $dy/dx$ as follows
\begin{equation}
\frac{df}{dx}\frac{dg}{df}\frac{dh}{dg}\frac{dy}{dh}=\frac{dy}{dx}
\end{equation}
But in principle we could also work backwards, from the output value $y$ to arrive at the same result,
\begin{equation}
\frac{dy}{dh}\frac{dh}{dg}\frac{dg}{df}\frac{df}{dx}=\frac{dy}{dx}
\end{equation}
Furthermore AD can be used on systems of equations and matrices. 
Tangent mode works forward from the left to right
\begin{equation}
\left(\left(\left(\frac{\partial x_1}{\partial x}\frac{\partial x_2}{\partial x_1}\right)\frac{\partial x_3}{\partial x_2}\right)\cdots\frac{\partial x_m}{\partial x_{m-1}}\right)\frac{\partial y}{\partial x_m}
\end{equation}
With adjoint mode we work backwards from the right
\begin{equation}
\frac{\partial x_1}{\partial x}\left(\frac{\partial x_2}{\partial x_2}\left(\frac{\partial x_3}{\partial x_2}\cdots\left(\frac{\partial x_m}{\partial x_{m-1}}\frac{\partial y}{\partial x_m}\right)\right)\right)
\end{equation}

\subsection{Tangent Mode}
In tangent mode we differentiate code working forwards starting with the trade inputs and follow the natural order of the original program. This method computes price sensitivities to one input at a time and we must call the tangent method several times, once for each input parameter.

When using tangent mode \emph{dot} notation is usually used to denote derivatives being differentiated with respect to the function input. For example given $y = f(x)$ then $y$ dot would indicate $\dot{y} = dy/dx$.
Consider the below simple function,
\begin{equation}
\begin{cases}
\text{Function: } y = 2x^2\\
\text{Tangent: } \dot{y} = 4x\dot{x}
\end{cases}
\label{eq:aad_function}
\end{equation}
In tangent mode $\dot{x}=dx/dx$ is specified as an input and used to enable/disable the tangent derivative calculation. Setting it to 1 in enables the derivative calculation giving
$dy/dx = 4x$, however when $\dot{x}= 0$ we have $dy/dx = 0$.

\subsection{Adjoint Mode}
When using adjoint mode we differentiate code in reverse order, starting with function outputs. 
Adjoint mode follows the reverse order of the original program, consequently we must compute the function value first (\emph{forward sweep}) and store the intermediate values before applying adjoint AD in reverse (\emph{back propagation}). This method shifts one function output at a time and generates derivatives exactly to machine precision for all price inputs in one go.

Adjoint mode is computed using \emph{bar} notation for derivatives to denote the variable is to be differentiated with respect to the function input. For example given $y = f(x)$ and working in reverse order gives $\bar{y} = dy/dx$
Once again let us consider same simple function from before,
\begin{equation}
\begin{cases}
\text{Function: } y = 2x^2\\
\text{Tangent: } \bar{y} = 4x\bar{x}
\end{cases}
\end{equation}
In adjoint mode $\bar{y} = dy/dy$ is specified as an input and allows us to enable/disable the adjoint derivative calculation. 

\subsection{Example}
Consider the function define in Eq.\ref{eq:aad_function} and compute the AD both using tangent and adjoint technique.
\begin{equation}
\begin{cases}
\text{Function: } f(x_1, x_2) = 2x_1^2 + 3x_2\\
\text{Solution: } \frac{df}{dx_1} = 4x_1, \text{ and } \frac{df}{dx_2}=3
\end{cases}
\end{equation}
When for example $x_1=2$ and $x_2 = 3$ we have,
\begin{equation}
\frac{df}{dx_1} = 8, \text{ and } \frac{df}{dx_2}=3
\end{equation}

\begin{question}
Consider a 5-years receiver Interest Rate Swap with a 1M notional, exchanging a fixed rate of 5\% with a flat 1\% LIBOR rate. The risk free rate for discounting is considered to be flat a 1.5\%.
Compute DV01 and PV01 with algorithmic differentiation using both tangent and adjoint modes. Compare the results.
\end{question}

\section{Asset Swap}

\begin{question}
Consider the 10-year German Bund DBR 0.5\% 2026 which is currently trading at a clean price of 104.58. 
Given that the 10-year EUR swap rate is 0.44\% what is the par-par asset swap spread for this bond? 
For this exercise assume the all Annuity Factors have a value of 10.0 for simplicity.
\end{question}
Recall the Asset Swap Spread $s$ can be calculated using 
Firstly we calculate the swap components giving 
The Par-Par adjustment is the dominating term and evaluates to
Par-Par Adjustment =

100 − 104.58
100 !
= −4.580%
We proceed to calculate the asset swap spread s as
s =
0.600% − 4.580%
10.0
= −0.3980%
or -39.80 basis points

Consider the 10-year Greek Government Bond GGB 3.0\% 2026 which is currently trading at a clean price of 75.280. Given that the 10-year EUR swap rate is 0.440\% what
is the par-par asset swap spread for this bond?
Using the Asset Swap Spread $s$ can be calculated using 
Again we calculate the swap components giving
The Par-Par adjustment evaluates to
Par-Par Adjustment =

100 − 75.280
100 !
= 24.72%
We proceed to calculate the asset swap spread s as
s =
25.60% + 24.72%
10.0
= 5.0320%
or 503.20 basis points


\section{Cap Volatility Bootstrap}

From the prices of different maturity caps, it is possible to $\color{red}{bootstrap}$ the volatility of each caplet, i.e. the volatility which refers to the forward rate corresponding to the caplet.

Let's \emph{strip} caplet volatilities from the following cap (flat) volatilities which refers to caps with 0.013 strike over EURIBOR-6M whose term structure is shown in Table\ref{tab:flat_volatilities}(right).

\begin{table}[htpb]
\begin{center}
\renewcommand{\arraystretch}{2}
\begin{tabular}{|c|c|}
\hline
Maturity & Volatility \\ \hline
1y & 44\% \\ \hline
2y & 45\% \\ \hline
3y & 44\% \\ \hline
4y & 41\% \\ \hline
5y & 39\% \\ \hline
\end{tabular}
\quad
\begin{tabular}{|c|c|}
\hline
Pillar & Rate \\ \hline
3m & 0.0002 \\ \hline
6m & 0.0007 \\ \hline
12m & 0.0025 \\ \hline
2y  & 0.0070 \\ \hline
3y & 0.0100 \\ \hline
5y & 0.0162 \\ \hline
\end{tabular}
\end{center}
\label{tab:flat_volatilities}
\caption{Left, flat volatilities table. Right, term structure of the considered Euribor-6M curve.}
\end{table}
The bootstrapping procedure proceeds has follows:
\begin{enumerate}
\item We start with the nearest instruments, i.e. the spot starting caplet with $6m$ maturity. For maturities shorter than the first quoted value we consider the volatility constant hence:
\begin{equation}
\sigma^{spot}(t_{0,6m})=\color{ipython-green}{\sigma^{flat}(t_{0,1y})}
\end{equation}
\item Let’s now price the $1y$ forward starting caplet with $6m$ maturity. Since market cap volatilities are quoted assuming \textbf{no-arbitrage} opportunity we can build the forward starting caplet as the difference of two caps:
\begin{equation}
\begin{gathered}
Cpl_{1y, 1y6m}(\sigma^{spot}_{1y6m})=Cap_{1y6m}-Cap_{1y} \\[0.3cm]
Cap_{1y6m}(\color{red}{\sigma^{flat}_{1y6m}})=Cpl_{0,6m}(\color{red}{\sigma^{flat}_{1y6m}}) + Cpl_{6m,1y}(\color{red}{\sigma^{flat}_{1y6m}}) + Cpl_{1y,1y6m}(\color{red}{\sigma^{flat}_{1y6m}}) \\[0.3cm]
Cap_{1y}(\textcolor{ipython-green}{\sigma^{flat}_{1y}})=Cpl_{0,6m}(\textcolor{ipython-green}{\sigma^{flat}_{1y}}) + Cpl_{6m,1y}(\color{ipython-green}{\sigma^{flat}_{1y}}) 
\end{gathered}
\end{equation}
Unfortunately the $18m$ volatility is NOT quoted on the market, so we can:
\begin{itemize}
  \item assume for the sake of simplicity that the volatility remains constant between $1y$ and $2y$ caps;
  \item use an interpolation method such as linear or cubic spline to get the $1y6m$ cap volatility.
\end{itemize}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.6\linewidth]{addons/flat_volatilities}
\end{center}
\label{fig:flat_volatilities}
\end{figure}

Once "estimated" $\sigma^{flat}_{1y6m}$ We will be able to solve a single volatility from previous Equation by using a Newton-Raphson or Brent method.

\item We can apply the same method for the $1y6m$ forward starting caplet to get the volatility, $\sigma^{flat}_{2y}$ is quoted so no interpolation is needed here.
\begin{equation}
\begin{gathered}
Cpl_{1y6m, 2y}(\sigma^{spot}_{2y})=Cap_{2y}-Cap_{1y6m} \\[0.3cm]
Cap_{2y}(\textcolor{ipython-green}{\sigma^{flat}_{2y}})=Cpl_{0,6m}(\textcolor{ipython-green}{\sigma^{flat}_{2y}}) + Cpl_{6m,1y}(\textcolor{ipython-green}{\sigma^{flat}_{2y}}) + \ldots + Cpl_{1y6m,2y}(\textcolor{ipython-green}{\sigma^{flat}_{2y}}) \\[0.3cm]
Cap_{1y6m}(\textcolor{ipython-green}{\sigma^{flat}_{1y6m}})=Cpl_{0,6m}(\textcolor{ipython-green}{\sigma^{flat}_{1y6m}}) + Cpl_{6m,1y}(\textcolor{ipython-green}{\sigma^{flat}_{1y6m}}) + Cpl_{1y,1y6m}(\textcolor{ipython-green}{\sigma^{flat}_{1y6m}})
\end{gathered}
\end{equation}

\item Keep iteratively to solve for all the remaining volatilities using the very same technique.
\end{enumerate}

\section{BPV}

\section{Asset Swap}

\section{Callable Bond}
Bonds with European call option just have a single possible call date. Let's denote the call date by $t_c$ and the notice time as $t_n$. Also, we denote the call price with $X$. 

In general, we can assume that \textbf{it is optimal for the issuer to minimize the value of the contract}. It means the issuer will exercise the option if the price of the callable bond exceeds the exercise price at the notice date. Otherwise, she will give up the option right and the callable bond price is equal to that of the non-option bond.

Denote by $r_b$ the \emph{break-even} interest rate which represents the rate value such that the issuer is indifferent between exercising the option or not.

It can be calculated by,
\begin{equation}
X\cdot D(t_n, t_c) - P(r,t_n)=0
\end{equation}
where $D(t_n, t_c)$ is the discount factor between notice and exercise dates and $P(r,t_n)$ the price of the callable bond an instant before the notice date.

We know the value of the callable bond $P(r,t_n)$ since it is equal to the value of the non-option bond. The solution of equation is the cross point between the two curves.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.5\linewidth]{addons/callable_bond}
	\end{center}
	\label{fig:callable_bond}
\end{figure}

\section{Jamshidian Decomposition}
An option on a portfolio of pure discount bonds can be decomposed into a portfolio of options on the individual discount bonds in the
portfolio.

Hence, we can think of the European Swaption as a sum of European
options on Zero-Coupon bonds. This method is called Jamshidian’s decomposition, and is mathematically explained as follows:
\begin{equation}
\max\left[\sum_{i=1}^n C_i p(r, t, s_i) - K, 0\right] = \sum_{i=1}^n C_i \max\left[p(r, t, s_i) - K_i, 0\right]
\label{eq:jamshidian_decomposition}
\end{equation}

Consider a European Swaption with strike rate $K$, maturity $T$ and nominal $FV$
with payment dates $T_i$ for $i = 1,\ldots, n$. Since the value of a floating rate bond is worth its face value, we can take it as an option on a bond paying $C_i = K_{s_i}$ with strike price $FV$. This option will be exercised when $r(T) < r^*$ where $r^*$ is the solution to
\begin{equation}
FV = \sum_{i=1}^n C_i p(r^*, T, T_i)
\end{equation}
This means that $FV$ is taken as a sum of discounted flows $C_i$ for a short rate $r^*$ at time $T$. To find the value of $r^*$ we have to discount all the Swap cash-flows, sum them up and let the sum be equal to the notional. We have to use the NewtonRaphson algorithm to follow this calculation $r^*$, that will be the correspondent level of $r$ for that equality to happen. 

Once $r^*$ is found, we have to calculate the discounted cash-flows substituting it in the discounting factor $e^{-r\Delta t}$ and let them be the strike prices of our call options on Swaps.
Afterwards, we calculate the payoff of the call options on the cash-flows with
the strike price mentioned and sum them up. The payoff of this sum of options
will thus be
\begin{equation}
\max\left[\sum_{i=1}^n C_ip(r, T, T_i)-FV, 0\right]
\end{equation}
which using Eq.\ref{eq:jamshidian_decomposition} we find is equivalent to
\begin{equation}
\sum_{i=1}^n C_i \max\left[p(r, T, T_i)-FV_i, 0\right]
\end{equation}
where $FV_i = p(r^*, T, T_i)$. 
Therefore, the Swaption is calculated as the sum of $n$ options on discounted bonds with the exercise price of the $i$th option equal to $FV_i$.

After the price of a European Swaption under the Hull-White model is calculated, we have to calibrate it against the market data. Usually this calibration method is carried out taking the target prices to match the ones given by the Black-76 or Normal-Black models and trying to get as close as possible to them.

\section{Reverse Floater}

* For instance, in September 2009, the short-term interest rate, the 3-month EURIBOR, **was at 0.5%**, and the forward curve was rising rather steeply, i.e. the implied forward 3-month EURIBOR in 3 years **was at 3.3%**. 
* The 3-year interest rate for a fixed-coupon bond **was at 3.5%** at the time. 
* It was possible to construct a 3-year reverse floater bond paying:

$$ 6\% - 2 \cdot \text{3M-EURIBOR}$$

(the coupon payments usually occur on a quarterly basis). 
* Should the 3-Month EURIBOR not move during the first year, the coupon would amount to $6\% - 2 \cdot 0.5\% = 5\%$. 
* Compared to a floating rate bond, the outperformance would be 4.5% for that period. 
%* After 3 years, the invested nominal is redeemed along with the last coupon.

Vega 

$$V_{\text{cap}}=F\Phi(d_1) - K\Phi(d_2)$$

$$\nu = \frac{\partial V_{\text{cap}}}{\partial\sigma} =
F\phi(d_1)$$

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.5\linewidth]{addons/reverse_floater_payoff}
	\end{center}
	\label{fig:reverse_floater_payoff}
\end{figure}

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.5\linewidth]{addons/cap_vega}
	\end{center}
	\label{fig:cap_vega}
\end{figure}

\section{Floating Rate Notes}
Floating rate bond or note (FRN) usually refers to an instrument whose coupon is based on a short term rate (3-month T-bill, 6-month LIBOR). Variable coupon rates are fixed in advance at reset dates, which are 3- or 6-month (interest payment period) earlier.

In this example we use an annual payment frequency but the extension to the quarterly or semi-annual frequency is straightforward.

Floating rate bond price with (\emph{unit notional amount}), $n$ maturity, annual frequency ($\tau=1$), and the first coupon rate predetermined at previous reset date ($C_{reset}$) is as follows.

\begin{equation}
\begin{aligned}
\textbf{FRN} & = D_{0,1}C_{reset} + \sum_{i=1}^nD_{0,i}f_{i,i+1} + D_{0,n}= \\
& = D_{0,1}C_{reset} + D_{0,2}f_{1,2} + \ldots + D_{0,n-1}f_{n-2,n-1}+ D_{0,n}(1+f_{n-1,n}) = \\
& = D_{0,1}C_{reset} + D_{0,2}\left(\frac{D_{0,1}}{D_{0,2}}-1\right) + \ldots \\
&\quad\ldots + D_{0,n-1}\left(\frac{D_{0,n-2}}{D_{0,n-1}}-1\right) + D_{0,n}\left(\frac{D_{0,n-1}}{D_{0,n}}-1\right) + D_{0,n} = \\
& = D_{0,1}C_{reset} + (D_{0,1} - D_{0,2}) + (D_{0,2} - D_{0,3}) + \ldots \\
&\quad\ldots + (D_{0,n-2} - D_{0,n-1}) + (D_{0,n-1} - D_{0,n}) + D_{0,n} = \boxed{D_{0,1} (1 +C_{reset})}
\end{aligned}
\end{equation}
where $f(t_1,t_2)$ denotes the forward rate between $t_1$ and $t_2$.

If the remaining maturity of the above \textbf{FRN} for example was 4.25 year, its price will be
\begin{equation}
\textbf{FRN} = D_{0,\frac{1}{4}}(1+C_{reset})
\end{equation}

If the remaining maturity of the above \textbf{FRN} was $(4 + \epsilon)$ year, in this case, the price would be

\begin{equation}
\begin{aligned}
\textbf{FRN} &= D_{0,1}f_{0,1}+ D_{0,2}f_{1,2} + \ldots + D_{0,n-1}f_{n-2,n-1} + D_{0,n}(1+f_{n-1,n}) = \\
& = D_{0,1}\left(\frac{D_{0,0}}{D_{0,1}}-1\right) + D_{0,2}\left(\frac{D_{0,1}}{D_{0,2}}-1\right) + \ldots \\
&\quad\ldots + D_{0,n-1}\left(\frac{D_{0,n-2}}{D_{0,n-1}}-1\right) + D_{0,n}\left(\frac{D_{0,n-1}}{D_{0,n}}-1\right) + D_{0,n} = \\
&= (D_{0,0}-D_{0,1})+(D_{0,1}-D_{0,2}) + \ldots \\
&\quad\ldots + (D_{0,n-2}-D_{0,n-1})+(D_{0,n-1}-D_{0,n})+D_{0,n} = 1
\end{aligned}
\end{equation}

The price of FRN has a range from \emph{par} to \emph{par} + full coupon. It is par right before the reset date and is $C$ right after the reset date (and is linear when pricing date is between two reset dates).

\begin{question}
Draw a plot showing the characteristic sawtooth behaviour of a floating rate note. The relevant insterest rates can be taken from \href{https://raw.githubusercontent.com/matteosan1/advanced\_financial\_modeling/master/input_files/libor.csv}{libor.csv}
\end{question}

\section{Girsanov Theorem}
Let’s start with a standard Brownian motion $W_t^{\mathcal{P}} = \mathcal{N}_{\mathcal{P}}(0,t)$ under a probability measure $\mathcal{P}$, and adapted to a filtration $\mathcal{F}_t$. In Fig.\ref{fig:brownian_motion_nodrift} 30 simulated path evolutions of $W_t^{\mathcal{P}}$ are shown, as expected there is no drfit.
	
\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.5\linewidth]{addons/brownian_motion_nodrift}
	\end{center}
	\label{fig:brownian_motion_nodrift}
	\caption{Thirty realization of the simple Brownian motion $W_t^{\mathcal{P}}$.}
\end{figure}

For exemplification, let us now construct a "drifty" process $Y_t=\mu t+\sigma W_t^{\mathcal{P}}\in \mathcal{N}_{\mathcal{P}}(\mu t, \sigma^2 t)$, that is a Wiener process with drift $\mu$ and diffusion $\sigma$; in other words, $\mathbb{E}^{\mathcal{P}}[Y_t]=\mu t$ and $\text{Var}^{\mathbb{P}}[Y_t]=\mathbb{E}^{\mathcal{P}}[Y^2_t]-\mathbb{E}^{\mathcal{P}}[Y_t]^2=\sigma^2 t$.

%Incidentally, note the terminology: the drift is not an expectation, but rather the rate of change in expectation, and the diffusion is not a standard deviation, but rather the square root of the rate of change in variance. 
Figure\ref{fig:brownian_motion_drift} shows 30 simulated paths for the evolution of $Y_t$ ($\mu = 0.8$ and $\sigma =1.25$). There the drift is visually apparent.
\begin{figure}[htbp]
\begin{center}
	\includegraphics[width=0.5\linewidth]{addons/brownian_motion_drift}
\end{center}
\label{fig:brownian_motion_drift}
	\caption{Thirty realization of the "drifty" Brownian motion $Y_t$.}
\end{figure}

We aim at applying a change of measure from $\mathcal{P}$ into a new probability $\mathcal{Q}$, such that $Y_t$ becomes driftless (a martingale) under $\mathcal{Q}: \mathbb{E}^{\mathcal{Q}}[Y_t]=0$, yet with the same diffusion as under $\mathcal{P}$: $\text{Var}^{\mathcal{Q}}[Y_t]=\sigma^2 t$

Let $\mu^{*}$ be a new drift and assume $\\gamma_t = \frac{\mu_t^{*}-\mu_t}{\sigma_t}$. According to the Girsanov Theorem the process
\begin{equation}
dW^{*}_t = -\gamma_t dt + dW_t
\end{equation}
is a Brownian motion under the new measure $\mathcal{Q}$, equivalent to $\mathcal{P}$, is defined by the Radon-Nikodym derivative
\begin{equation}
\cfrac{d\mathcal{Q}}{d\mathcal{P}} = \exp\left(-\frac{1}{2}\int_0^t\gamma_s^2 ds + \int_0^t\gamma_s dW_s\right)
\end{equation}

\begin{question}
Consider a Wiener process with drift $\mu=0.05$ and diffusion coefficient $\sigma=0.2$. Determine the appropriate transformation, according to the Girsanov Theorem which makes the original process driftless. Verify that applying the Radon-Nikodym to the a simulated path of the process the drift indeed disappear.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.5\linewidth]{addons/brownian_motion_girsanov}
	\end{center}
	\label{fig:brownian_motion_girsanov}
\end{figure}
\end{question}

\begin{question}
Given an underlying asset $S$ which currently is valued 100 simulate $N$ possible realization of the random variable $S$ both under the \emph{physical} probability measure and the 
and a 1 year call option on that asset with strike $K=120$ determine 

Other  Consider a Wiener process with drift $\mu=0.05$ and diffusion coefficient $\sigma=0.2$. Determine the appropriate transformation, according to the Girsanov Theorem which makes the original process driftless. Verify that applying the Radon-Nikodym to the a simulated path of the process the drift indeed disappear.

mu = 0.05
r = 0.01
sigma = 0.20
l = (mu-r)/sigma
S0 = 100
K = 120
T = 1
M = 252
dt = T/M
N = 10000
\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.5\linewidth]{addons/brownian_motion_girsanov}
	\end{center}
	\label{fig:brownian_motion_girsanov}
\end{figure}
\end{question}












\section{Importance Sampling}
Assume we want to calculate the expectation $\mathbb{E}[f(X)]$
\begin{equation}
\mathbb{E}[f(X)] = \int_{-\infty}^\infty f(x)p(x)dx
\end{equation}
where $p(x)$ is the probability density function associated to the random variable $X$.

We can approximate this expectation using numerical approximation, i.e. Monte Carlo simulation, by sampling $n$ random values from the distribution $p$ and then calculating the sample mean as:
\begin{equation}
\bar{f}(x) = \frac{1}{n}\sum_i f(x_i)
\end{equation}

The idea behind \textbf{importance sampling} is to use a simple re-formulation trick and write the expectation in a slightly different form
\begin{equation}
\mathbb{E}[f(X)] = \int_{-\infty}^\infty f(x)\frac{p(x)}{q(x)}q(x)dx
\end{equation}
giving the expectation of $f(x)\frac{p(x)}{q(x)}$ over the distribution $q$. And with that, allowing us to calculate the sample mean by sampling from $q$:
\begin{equation}
\bar{f}(x) = \frac{1}{n}\sum_i f(x_i)\frac{p(x)}{q(x)}
\label{eq:reformulated_expectation}
\end{equation}

\subsection{Variance Reduction}
From probability theory we know that the variance of the standard Monte Carlo estimator is given by:
\begin{equation}
\cfrac{1}{n}\cdot\text{Var}[f(x)] = \cfrac{1}{n}\cdot\mathbb{E}[(f(X)-\mathbb{E}[f(X)])^2]
\end{equation}

Hence the variance for the re-formulated importance sampling estimator in Eq.\ref{eq:reformulated_expectation} is:
\begin{equation}
\cfrac{1}{n}\cdot\text{Var}\left[\cfrac{p(x)}{q(x)}f(x)\right]
\end{equation}

This give us a hint on how to find a way to reduce the variance. And indeed it is relatively easy to see that this variance could be reduced to 0 by choosing $q$ as:
\begin{equation}
\begin{aligned}
q(x)&=\cfrac{f(X)p(x)}{\mathbb{E}[f(X)]} \implies \cfrac{1}{n}\cdot\text{Var}[\mathbb{E}[f(X)]] = \cfrac{1}{n}\cdot\mathbb{E}[(\mathbb{E}[f(X)]-\mathbb{E}[\mathbb{E}[f(X)]])^2]=\\
&=\cfrac{1}{n}\cdot\mathbb{E}[(\mathbb{E}[f(X)]-\mathbb{E}[f(X)])^2] = 0
\end{aligned}
\end{equation}

Naturally, we don’t know $\mathbb{E}[f(X)]$, as the reason we are doing this sampling after all is to find the expectation of $f$.
However, we can think of the denominator of the previous expression as some normalisation constant, and consider to construct $q$ such that it has \textbf{high} density wherever $f(x)p(x)$ is \textbf{high}.

\subsection{Practical Example}
For the sake of demonstration, we choose $f=\mathcal{N}(5, 1)$, and the probability distribution $p=\mathcal{N}(9,2)$ which do not overlap too well, see Fig.\ref{fig:f_and_p}.
\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.5\linewidth]{addons/f_and_p}
\end{center}
\label{fig:f_and_p}
\end{figure}

To approximate numerically the expectation, as stated above, we would now sample values $x_i$ from the distribution $p$, and compute the mean of $f(x_i)$.

Intuitively one can see why sampling from this distribution is a bad idea: for most values sampled from $p$, $f$ will be close to 0, but for a few sampled values $f$ will be very large, thus we obtain a large variance.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.5\linewidth]{addons/bad_sampling}
\end{center}
\label{fig:bad_sampling}
\end{figure}

Looking at Fig.|\ref{fig:bad_sampling} it is apparent how the vast majority of samples piles up at 0 (notice the logarithmic scale of the plot). 
Therefore, as outlined above, to make the sampling more efficient, we can try a new distribution $q = \mathcal{N}(5.8, 1)$, which satisfies the criterion that its pdf is high in regions where $f(x)p(x)$ is high, see Fig|\ref{fig:fp_and_q}.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.4\linewidth]{addons/fp_and_q}
\includegraphics[width=0.4\linewidth]{addons/good_sampling}
\end{center}
\label{fig:fp_and_q}
\end{figure}

The resulting sampling is much better since the values are now clustered around 0.03. Comparing the estimates of the expectation in the two cases shows that the value is essentially the same, but the variance almost a factor 200 lower when using the importance sampling.
\begin{ioutput}
Numerical Simulation: mean 0.03611, variance 0.00759
Importance Sampling: mean 0.03603, variance 0.00003
\end{ioutput}
Note that in general it’s not trivial at all to find $q$, and certainly there are much more difficult real-word scenarios. For this example I actually plotted $p(x)f(x)$ and then picked a $q$ which resembled it best.

\begin{question}
Implement the importance sampling example outlined above, trying to reproduce the results quoted in the text.
\end{question}
\begin{question}
Estimate how unlucky is a 25 standard deviation return
\begin{equation*}
\theta := P(X\geq 25) = \mathbb{E}[\mathbbm{1}_{X\geq 25}]  \quad\text{where } X\sim \mathcal{N}(0, 1)
\end{equation*}
\end{question}
\begin{question}
Consider a one year ($T=1$) call option with $S_0=100$ , $K=170$,  $\sigma=0.2$, and $r=0.06$. The option is far out of the money, assuming we need to estimate its valye using Monte Carlo simulation, improve the efficiency of the calculation with importance sampling.

\noindent
Interesting reference \emph{Variance Reduction Techniques of Importance Sampling Monte Carlo Methods for Pricing Options}, 
Journal of Mathematical Finance, 2013, 3, 431-436.
\end{question}


\end{document}
